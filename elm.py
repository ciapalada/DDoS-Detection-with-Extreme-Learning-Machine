# -*- coding: utf-8 -*-
"""ELM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12c7S65g8mPpZ6Z1gT0SUKxWc7gceTjGi
"""

class elm():
   #initialization the model 
   #hidden_nodes = number of hidden layer nodes
   #activation_function = this study used sigmoid and ReLu
   #x = input layer
   #y = output layer
   #C = regulation number 
    def __init__(self, hidden_nodes, activation_function,  x, y, C, elm_type,
                 one_hot=True, random_type='normal'):
        self.hidden_nodes = hidden_nodes
        self.activation_function = activation_function
        self.random_type = random_type
        self.x = x
        self.y = y
        self.C = C
        self.class_num = np.unique(self.y).shape[0]     
        self.beta = np.zeros((self.hidden_nodes, self.class_num))   
        self.elm_type = elm_type
        self.one_hot = one_hot

       #one hot encoding
        if elm_type == 'clf' and self.one_hot:
            self.one_hot_label = np.zeros((self.y.shape[0], 
                                           self.class_num))
            for i in range(self.y.shape[0]):
                self.one_hot_label[i, int(self.y[i])] = 1

                
        # Randomly generate the weight  and bias from input to hidden layer
        # 'normal': normal distribution
        if self.random_type == 'normal':
            self.W = np.random.normal(loc=0, scale=0.5, size=(self.hidden_nodes,
                                                              self.x.shape[1]))
            self.b = np.random.normal(loc=0, scale=0.5, size=(self.hidden_nodes, 
                                                              1))
            

    # compute the output hidden layer according to activation function
    def __input2hidden(self, x):
        self.temH = np.dot(self.W, x.T) + self.b

        if self.activation_function == 'sigmoid':
            self.H = 1/(1 + np.exp(-self.temH))

        if self.activation_function == 'relu':
            self.H = self.temH * (self.temH > 0)

        return self.H

    # compute the hidden output
    def __hidden2output(self, H):
        self.output = np.dot(H.T, self.beta)
        return self.output

    
    #Fit method for train the model
    #compute input weight 
    def fit(self, algorithm):
        self.time1 = time.clock()   # compute running time
        self.H = self.__input2hidden(self.x)
        if self.elm_type == 'clf':
            if self.one_hot:
                self.y_temp = self.one_hot_label
            else:
                self.y_temp = self.y

        # algorithm (using regularization)
        if algorithm == 'solution':
            self.tmp1 = inv(np.eye(self.H.shape[0])/self.C + np.dot(self.H, self.H.T))
            self.tmp2 = np.dot(self.H.T, self.tmp1)
            self.beta = np.dot(self.tmp2.T, self.y_temp)
        self.time2 = time.clock()

        # compute the results
        self.result = self.__hidden2output(self.H)
        # Using softmax for the result
        if self.elm_type == 'clf':
            self.result = np.exp(self.result)/np.sum(np.exp(self.result), axis=1).reshape(-1, 1)

        # Evaluate training results
        # compute the accuracy

        if self.elm_type == 'clf':
            self.y_ = np.where(self.result == np.max(self.result, axis=1).reshape(-1, 1))[1]
            self.correct = 0
            for i in range(self.y.shape[0]):
                if self.y_[i] == self.y[i]:
                    self.correct += 1
            self.train_score = self.correct/self.y.shape[0]

        train_time = str(self.time2 - self.time1)
        return self.beta, self.train_score, train_time

   #compute the prediction /result given data
    def predict(self, x):
        self.H = self.__input2hidden(x)
        self.y_ = self.__hidden2output(self.H)
        if self.elm_type == 'clf':
            self.y_ = np.where(self.y_ == np.max(self.y_, axis=1).reshape(-1, 1))[1]

        return self.y_

    #compute accuracy accrording to given data and label 
    def score(self, x, y):
        self.prediction = self.predict(x)
        if self.elm_type == 'clf':
            self.correct = 0
            for i in range(y.shape[0]):
                if self.prediction[i] == y[i]:
                    self.correct += 1
            self.test_score = self.correct/y.shape[0]
        return self.test_score


# built model, input the initialization data and train
model = elm(hidden_nodes=100, activation_function='relu', random_type='normal', 
            x=X_train, y=y_train, C=0.1, elm_type='clf')
beta, train_accuracy, running_time = model1.fit('solution')
print("classifier beta:\n", beta)
print("classifier train accuracy:", train_accuracy)
print('classifier running time:', running_time)


#show the confusion matrix and testing score based on prediction result
prediction = model1.predict(X_test)
print(confusion_matrix(y_test, prediction)) 
print(classification_report(y_test, prediction))
print("classifier test prediction:", prediction)
print('classifier test accuracy:', model1.score(X_test, y_test))